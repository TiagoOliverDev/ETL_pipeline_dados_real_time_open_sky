# ‚úàÔ∏è Flight Data Global Pipeline

Pipeline ETL para coleta, processamento e armazenamento de dados de voos em tempo real, utilizando Python, Apache Airflow e PostgreSQL.

---

## üìö Vis√£o Geral

- **Extra√ß√£o:** Coleta dados da API OpenSky Network e salva em JSON.
- **Transforma√ß√£o:** Normaliza, limpa e transforma os dados em CSV.
- **Carga:** Insere os dados processados em um banco PostgreSQL.
- **Orquestra√ß√£o:** Todo o fluxo √© automatizado via Apache Airflow.

---

## üóÇÔ∏è Estrutura do Projeto

```bash
ETL_pipeline_dados_real_time_open_sky/
‚îú‚îÄ‚îÄ config/
‚îÇ   ‚îî‚îÄ‚îÄ settings.py
‚îú‚îÄ‚îÄ dags/
‚îÇ   ‚îî‚îÄ‚îÄ flight_data_dag.py
‚îú‚îÄ‚îÄ data/
‚îÇ   ‚îú‚îÄ‚îÄ raw/
‚îÇ   ‚îî‚îÄ‚îÄ processed/
‚îú‚îÄ‚îÄ logs/
‚îú‚îÄ‚îÄ notebooks/
‚îú‚îÄ‚îÄ plugins/
‚îú‚îÄ‚îÄ src/
‚îÇ   ‚îú‚îÄ‚îÄ db/
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ db_connections.py
‚îÇ   ‚îú‚îÄ‚îÄ etl/
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ extract_data.py
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ json_loader.py
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ load_data.py
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ transform_data.py
‚îÇ   ‚îú‚îÄ‚îÄ utils/
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ logger.py
‚îú‚îÄ‚îÄ tests/
‚îú‚îÄ‚îÄ .env.example
‚îú‚îÄ‚îÄ .gitignore
‚îú‚îÄ‚îÄ .dockerignore
‚îú‚îÄ‚îÄ docker-compose.yml
‚îú‚îÄ‚îÄ Dockerfile
‚îú‚îÄ‚îÄ requirements.txt
‚îî‚îÄ‚îÄ main.py

```


## üóÇÔ∏è Estrutura do Processamento

```bash

    +----------------+              +------------------+               +-------------------+
    |  Producer API  | --JSON-->    |   Kafka Topic    | --> Stream -->| Spark Structured  |
    | (OpenSky + ETL)|              | flight-data-raw  |               | Streaming + Write |
    +----------------+              +------------------+               | to PostgreSQL     |
                                                                           +-- UPSERT (merge/update)

```



---

## ‚öôÔ∏è Configura√ß√£o do Ambiente

### 1. **Pr√©-requisitos**

- [Docker](https://www.docker.com/)
- [Docker Compose](https://docs.docker.com/compose/)
- Python 3.11+ (apenas para execu√ß√£o manual)

```
Crie um banco de dados local para acompanhar os dados caindo, insira as cred√™nciais dele no .env e crie a tabela:

CREATE TABLE IF NOT EXISTS flight_data (
    icao24 VARCHAR(10) NOT NULL,
    callsign VARCHAR(10),
    origin_country VARCHAR(100),
    latitude DOUBLE PRECISION,
    longitude DOUBLE PRECISION,
    velocity DOUBLE PRECISION,
    heading DOUBLE PRECISION,
    baro_altitude DOUBLE PRECISION,
    geo_altitude DOUBLE PRECISION,
    on_ground BOOLEAN,
    time_position TIMESTAMP WITHOUT TIME ZONE NOT NULL,
    last_contact TIMESTAMP WITHOUT TIME ZONE,
    record_timestamp TIMESTAMP WITHOUT TIME ZONE,
    PRIMARY KEY (icao24, time_position)
);


```

### 2. **Clone o Reposit√≥rio**

```bash
git clone https://github.com/TiagoOliverDev/ETL_Pipeline_de_Dados_Climaticos
cd ETL_Pipeline_de_Dados_Climaticos
```

### 3. **Crie o Arquivo `.env`**

Baseie-se no modelo .env.example

### 4. **Suba o Ambiente com Docker Compose**

```bash
docker-compose up --build
```

- O Airflow estar√° dispon√≠vel em: [http://localhost:8080](http://localhost:8080/)
- Usu√°rio e senha definidos no `.env`

### 5. **Ative a DAG no Airflow**

1. Acesse a interface web do Airflow
2. Ative a DAG `flight_data_pipeline`
3. V√° em admin - connections e adicione as cred√™nciais do banco de dados (pode ser local)
4. Voc√™ pode disparar manualmente ou aguardar a execu√ß√£o autom√°tica

---

## üõ†Ô∏è Execu√ß√£o Manual (fora do Airflow)

Se desejar rodar o pipeline manualmente:

```bash
python main.py
```

---

## üß© Principais Arquivos

- `dags/flight_data_dag.py`: DAG principal do Airflow
- `src/etl/extract_data.py`: Fun√ß√£o de extra√ß√£o da API
- `src/etl/transform_data.py`: Fun√ß√µes de transforma√ß√£o
- `src/etl/load_data.py`: Fun√ß√£o de carga no PostgreSQL
- `config/settings.py`: Par√¢metros globais do pipeline
- `main.py`: Execu√ß√£o manual do pipeline

---

## üìù Observa√ß√µes

- Os diret√≥rios `data/raw`, `data/processed` e `logs` est√£o no `.gitignore`
- A tabela √© criada automaticamente no banco se n√£o existir
- O Airflow usa a conex√£o nomeada `postgres_etl_conn`

---

## üìö Licen√ßa

Este projeto √© open-source e est√° sob a licen√ßa MIT.

---

## üë©‚Äçüíª Desenvolvido por

Tiago Oliveira ‚Äì Analista desenvolvedor e Engenheiro de dados em forma√ß√£o

- üíº¬†[LinkedIn](https://www.linkedin.com/in/tiago-oliveira-49a2a6205/)
- üíª¬†[GitHub](https://github.com/TiagoOliverDev)

